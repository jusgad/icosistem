"""
${message}

Ecosistema de Emprendimiento - Database Migration
================================================

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}
Migration Type: ${'Auto-generated' if up_revision else 'Manual'}
Author: ${author if author else 'Sistema Autom√°tico'}
Environment: ${environment if environment else 'development'}

Description:
${message}

Schema Changes Summary:
- Tables: ${tables_modified if tables_modified else 'TBD'}
- Columns: ${columns_modified if columns_modified else 'TBD'}  
- Indexes: ${indexes_modified if indexes_modified else 'TBD'}
- Constraints: ${constraints_modified if constraints_modified else 'TBD'}

Migration Safety Level: ${'HIGH' if 'DROP' in message.upper() or 'DELETE' in message.upper() else 'MEDIUM' if 'ALTER' in message.upper() else 'LOW'}

Prerequisites:
- Database backup completed: ${backup_required if backup_required else 'No'}
- Downtime required: ${downtime_required if downtime_required else 'No'}
- Data migration needed: ${data_migration if data_migration else 'No'}

Post-Migration Tasks:
- Update application cache: ${clear_cache if clear_cache else 'No'}
- Restart services: ${restart_services if restart_services else 'No'}
- Run data validation: ${validate_data if validate_data else 'No'}

Rollback Instructions:
- This migration CAN be rolled back safely
- Estimated rollback time: ${rollback_time if rollback_time else '< 1 minute'}
- Data loss potential: ${data_loss_risk if data_loss_risk else 'None'}

Contact Information:
- Technical Lead: devops@ecosistema.com
- Database Admin: dba@ecosistema.com
- Emergency Contact: oncall@ecosistema.com

"""

import logging
import os
import sys
from datetime import datetime
from typing import Optional, List, Dict, Any

from alembic import op
import sqlalchemy as sa
from sqlalchemy import text, inspect, MetaData
from sqlalchemy.engine import Connection
from sqlalchemy.exc import SQLAlchemyError
${imports if imports else ""}

# ============================================================================
# CONFIGURACI√ìN DE LOGGING
# ============================================================================

# Configurar logger espec√≠fico para esta migraci√≥n
logger = logging.getLogger(f'alembic.migration.${up_revision}')
logger.setLevel(logging.INFO)

# Handler para consola si no existe
if not logger.handlers:
    console_handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)


# ============================================================================
# METADATA DE LA MIGRACI√ìN
# ============================================================================

# revision identifiers, used by Alembic.
revision = ${repr(up_revision)}
down_revision = ${repr(down_revision)}
branch_labels = ${repr(branch_labels)}
depends_on = ${repr(depends_on)}

# Migration metadata
migration_info = {
    'id': revision,
    'description': ${repr(message)},
    'created_at': '${create_date}',
    'author': '${author if author else "Sistema Autom√°tico"}',
    'environment': os.getenv('ALEMBIC_ENV', 'development'),
    'safety_level': '${'HIGH' if 'DROP' in message.upper() or 'DELETE' in message.upper() else 'MEDIUM' if 'ALTER' in message.upper() else 'LOW'}',
}

# Configuraci√≥n espec√≠fica de la migraci√≥n
MIGRATION_CONFIG = {
    'requires_backup': ${str('DROP' in message.upper() or 'DELETE' in message.upper()).lower()},
    'requires_downtime': ${str('ADD COLUMN' not in message.upper() and 'ALTER' in message.upper()).lower()},
    'batch_size': 1000,
    'timeout_seconds': 300,
    'validate_data_integrity': True,
    'clear_cache_after': ${str('INDEX' in message.upper() or 'CONSTRAINT' in message.upper()).lower()},
}


# ============================================================================
# UTILIDADES DE MIGRACI√ìN
# ============================================================================

def get_connection() -> Connection:
    """Obtiene la conexi√≥n actual de Alembic."""
    return op.get_bind()


def log_migration_start(operation: str) -> None:
    """Registra el inicio de una operaci√≥n de migraci√≥n."""
    logger.info(f"="*60)
    logger.info(f"INICIANDO {operation.upper()} - Migraci√≥n {revision}")
    logger.info(f"Descripci√≥n: ${message}")
    logger.info(f"Ambiente: {migration_info['environment']}")
    logger.info(f"Nivel de seguridad: {migration_info['safety_level']}")
    logger.info(f"="*60)


def log_migration_end(operation: str, success: bool = True) -> None:
    """Registra el final de una operaci√≥n de migraci√≥n."""
    status = "COMPLETADO" if success else "FALLIDO"
    logger.info(f"="*60)
    logger.info(f"{operation.upper()} {status} - Migraci√≥n {revision}")
    logger.info(f"Tiempo: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"="*60)


def validate_prerequisites() -> bool:
    """
    Valida que se cumplan todos los prerequisitos antes de la migraci√≥n.
    """
    try:
        logger.info("Validando prerequisitos de migraci√≥n...")
        
        connection = get_connection()
        
        # Validar conexi√≥n a base de datos
        result = connection.execute(text("SELECT 1"))
        result.fetchone()
        logger.info("‚úì Conexi√≥n a base de datos validada")
        
        # Validar que no hay procesos bloqueantes
        locks_query = text("""
            SELECT count(*) as lock_count 
            FROM pg_locks l 
            JOIN pg_stat_activity a ON l.pid = a.pid 
            WHERE l.granted = false
        """)
        result = connection.execute(locks_query)
        lock_count = result.fetchone()[0]
        
        if lock_count > 0:
            logger.warning(f"Se detectaron {lock_count} bloqueos en la base de datos")
            
        logger.info("‚úì Prerequisitos validados exitosamente")
        return True
        
    except Exception as e:
        logger.error(f"‚úó Error validando prerequisitos: {e}")
        return False


def validate_data_integrity_pre() -> bool:
    """
    Valida la integridad de los datos antes de la migraci√≥n.
    """
    try:
        logger.info("Validando integridad de datos pre-migraci√≥n...")
        
        connection = get_connection()
        
        # Validar constraints principales
        constraints_query = text("""
            SELECT 
                conname as constraint_name,
                contype as constraint_type,
                conrelid::regclass as table_name
            FROM pg_constraint 
            WHERE contype IN ('f', 'c', 'u', 'p')
            AND NOT convalidated
        """)
        
        result = connection.execute(constraints_query)
        invalid_constraints = result.fetchall()
        
        if invalid_constraints:
            logger.warning(f"Se encontraron {len(invalid_constraints)} constraints no validados")
            for constraint in invalid_constraints:
                logger.warning(f"  - {constraint.constraint_name} en {constraint.table_name}")
        else:
            logger.info("‚úì Todos los constraints est√°n validados")
        
        # Validar integridad referencial b√°sica (ejemplo para el ecosistema)
        orphan_checks = [
            ("Usuarios hu√©rfanos", """
                SELECT COUNT(*) FROM users u 
                LEFT JOIN entrepreneurs e ON u.id = e.user_id 
                LEFT JOIN allies a ON u.id = a.user_id 
                LEFT JOIN clients c ON u.id = c.user_id 
                WHERE u.role_type IN ('entrepreneur', 'ally', 'client') 
                AND e.id IS NULL AND a.id IS NULL AND c.id IS NULL
            """),
            ("Proyectos sin emprendedor", """
                SELECT COUNT(*) FROM projects p 
                LEFT JOIN entrepreneurs e ON p.entrepreneur_id = e.id 
                WHERE e.id IS NULL
            """),
            ("Reuniones sin participantes", """
                SELECT COUNT(*) FROM meetings m 
                LEFT JOIN meeting_participants mp ON m.id = mp.meeting_id 
                WHERE mp.id IS NULL
            """),
        ]
        
        for check_name, query in orphan_checks:
            try:
                result = connection.execute(text(query))
                count = result.fetchone()[0]
                if count > 0:
                    logger.warning(f"  - {check_name}: {count} registros")
                else:
                    logger.info(f"‚úì {check_name}: OK")
            except Exception as e:
                logger.warning(f"No se pudo ejecutar validaci√≥n '{check_name}': {e}")
        
        logger.info("‚úì Validaci√≥n de integridad completada")
        return True
        
    except Exception as e:
        logger.error(f"‚úó Error validando integridad de datos: {e}")
        return False


def validate_data_integrity_post() -> bool:
    """
    Valida la integridad de los datos despu√©s de la migraci√≥n.
    """
    try:
        logger.info("Validando integridad de datos post-migraci√≥n...")
        
        connection = get_connection()
        
        # Verificar que no se perdieron datos cr√≠ticos
        critical_tables = ['users', 'entrepreneurs', 'allies', 'clients', 'projects']
        
        for table in critical_tables:
            try:
                result = connection.execute(text(f"SELECT COUNT(*) FROM {table}"))
                count = result.fetchone()[0]
                logger.info(f"‚úì Tabla {table}: {count} registros")
            except Exception as e:
                logger.error(f"‚úó Error verificando tabla {table}: {e}")
                return False
        
        # Ejecutar ANALYZE para actualizar estad√≠sticas
        connection.execute(text("ANALYZE"))
        logger.info("‚úì Estad√≠sticas de tablas actualizadas")
        
        logger.info("‚úì Validaci√≥n post-migraci√≥n completada")
        return True
        
    except Exception as e:
        logger.error(f"‚úó Error en validaci√≥n post-migraci√≥n: {e}")
        return False


def backup_critical_data() -> Optional[str]:
    """
    Realiza backup de datos cr√≠ticos antes de operaciones peligrosas.
    """
    if not MIGRATION_CONFIG['requires_backup']:
        return None
        
    try:
        logger.info("Realizando backup de datos cr√≠ticos...")
        
        connection = get_connection()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_schema = f"backup_{timestamp}"
        
        # Crear schema de backup
        connection.execute(text(f"CREATE SCHEMA IF NOT EXISTS {backup_schema}"))
        
        # Tablas cr√≠ticas a respaldar
        critical_tables = ['users', 'entrepreneurs', 'allies', 'projects', 'meetings']
        
        for table in critical_tables:
            try:
                backup_table = f"{backup_schema}.{table}_backup"
                connection.execute(text(f"""
                    CREATE TABLE {backup_table} AS 
                    SELECT * FROM {table}
                """))
                logger.info(f"‚úì Backup creado: {backup_table}")
            except Exception as e:
                logger.warning(f"No se pudo respaldar {table}: {e}")
        
        logger.info(f"‚úì Backup completado en schema: {backup_schema}")
        return backup_schema
        
    except Exception as e:
        logger.error(f"‚úó Error creando backup: {e}")
        return None


def cleanup_backup(backup_schema: Optional[str]) -> None:
    """
    Limpia el backup temporal despu√©s de una migraci√≥n exitosa.
    """
    if not backup_schema:
        return
        
    try:
        # En producci√≥n, mantener backups por m√°s tiempo
        env = migration_info['environment']
        if env == 'production':
            logger.info(f"Manteniendo backup {backup_schema} para producci√≥n")
            return
            
        connection = get_connection()
        connection.execute(text(f"DROP SCHEMA IF EXISTS {backup_schema} CASCADE"))
        logger.info(f"‚úì Backup temporal {backup_schema} eliminado")
        
    except Exception as e:
        logger.warning(f"No se pudo limpiar backup {backup_schema}: {e}")


def execute_with_retry(operation_func, max_retries: int = 3, delay: int = 1) -> bool:
    """
    Ejecuta una operaci√≥n con reintentos en caso de error.
    """
    import time
    
    for attempt in range(max_retries):
        try:
            operation_func()
            return True
        except Exception as e:
            logger.warning(f"Intento {attempt + 1}/{max_retries} fall√≥: {e}")
            if attempt < max_retries - 1:
                time.sleep(delay * (attempt + 1))  # Backoff exponencial
            else:
                logger.error(f"Operaci√≥n fall√≥ despu√©s de {max_retries} intentos")
                raise
    return False


def clear_application_cache() -> None:
    """
    Limpia cach√© de aplicaci√≥n si es necesario.
    """
    if not MIGRATION_CONFIG['clear_cache_after']:
        return
        
    try:
        logger.info("Limpiando cach√© de aplicaci√≥n...")
        
        connection = get_connection()
        
        # Limpiar cache de sesiones si existe
        try:
            connection.execute(text("DELETE FROM cache_data WHERE expires_at < NOW()"))
            logger.info("‚úì Cache de datos limpiado")
        except Exception:
            pass  # La tabla podr√≠a no existir
        
        # Invalidar cache de aplicaci√≥n (Redis, Memcached, etc.)
        # Aqu√≠ se integrar√≠a con el sistema de cache espec√≠fico
        
        logger.info("‚úì Cache de aplicaci√≥n limpiado")
        
    except Exception as e:
        logger.warning(f"Error limpiando cache: {e}")


def send_migration_notification(operation: str, success: bool, details: str = "") -> None:
    """
    Env√≠a notificaci√≥n sobre el estado de la migraci√≥n.
    """
    try:
        env = migration_info['environment']
        if env == 'testing':
            return  # No enviar notificaciones en testing
            
        status = "EXITOSA" if success else "FALLIDA"
        message = f"""
üîÑ Migraci√≥n {operation.upper()} {status}

üìã **Detalles:**
- Revision: `{revision}`
- Ambiente: `{env.upper()}`
- Descripci√≥n: ${message}
- Tiempo: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{details}
        """
        
        # Aqu√≠ se integrar√≠a con Slack, Teams, email, etc.
        logger.info(f"Notificaci√≥n: {message.strip()}")
        
    except Exception as e:
        logger.warning(f"Error enviando notificaci√≥n: {e}")


# ============================================================================
# FUNCI√ìN DE UPGRADE
# ============================================================================

def upgrade() -> None:
    """
    Ejecuta la migraci√≥n hacia adelante (upgrade).
    
    Esta funci√≥n contiene todas las operaciones DDL para actualizar
    la base de datos a la nueva versi√≥n del esquema.
    """
    backup_schema = None
    
    try:
        log_migration_start("UPGRADE")
        
        # 1. Validar prerequisitos
        if not validate_prerequisites():
            raise Exception("Prerequisitos no cumplidos")
        
        # 2. Validar integridad pre-migraci√≥n
        if MIGRATION_CONFIG['validate_data_integrity']:
            if not validate_data_integrity_pre():
                logger.warning("Advertencias en validaci√≥n de integridad pre-migraci√≥n")
        
        # 3. Crear backup si es necesario
        backup_schema = backup_critical_data()
        
        # 4. Ejecutar operaciones de migraci√≥n
        logger.info("Ejecutando operaciones de migraci√≥n...")
        
        # ====================================================================
        # OPERACIONES DE MIGRACI√ìN - GENERADAS AUTOM√ÅTICAMENTE
        # ====================================================================
        ${upgrades if upgrades else "# TODO: Agregar operaciones de migraci√≥n"}
        
        # Ejemplo de operaciones comunes:
        # 
        # # Crear nueva tabla
        # op.create_table('nueva_tabla',
        #     sa.Column('id', sa.Integer, primary_key=True),
        #     sa.Column('nombre', sa.String(255), nullable=False),
        #     sa.Column('created_at', sa.DateTime, default=sa.func.now()),
        # )
        # 
        # # Agregar columna
        # op.add_column('tabla_existente', 
        #     sa.Column('nueva_columna', sa.String(100), nullable=True)
        # )
        # 
        # # Crear √≠ndice
        # op.create_index('idx_tabla_columna', 'tabla', ['columna'])
        # 
        # # Agregar constraint
        # op.create_foreign_key('fk_tabla_referencia', 'tabla', 'referencia', 
        #                      ['referencia_id'], ['id'])
        
        logger.info("‚úì Operaciones de migraci√≥n completadas")
        
        # 5. Validar integridad post-migraci√≥n
        if MIGRATION_CONFIG['validate_data_integrity']:
            if not validate_data_integrity_post():
                raise Exception("Fallo en validaci√≥n de integridad post-migraci√≥n")
        
        # 6. Limpiar cache si es necesario
        clear_application_cache()
        
        # 7. Limpiar backup temporal
        cleanup_backup(backup_schema)
        
        # 8. Enviar notificaci√≥n de √©xito
        send_migration_notification("upgrade", True, 
            f"‚úÖ Migraci√≥n aplicada exitosamente en {migration_info['environment']}")
        
        log_migration_end("UPGRADE", True)
        
    except Exception as e:
        logger.error(f"‚úó Error durante upgrade: {e}")
        
        # Mantener backup en caso de error
        if backup_schema:
            logger.info(f"Backup preservado para recuperaci√≥n: {backup_schema}")
        
        # Enviar notificaci√≥n de error
        send_migration_notification("upgrade", False, 
            f"‚ùå Error: {str(e)}\nüíæ Backup disponible: {backup_schema or 'No'}")
        
        log_migration_end("UPGRADE", False)
        raise


# ============================================================================
# FUNCI√ìN DE DOWNGRADE
# ============================================================================

def downgrade() -> None:
    """
    Ejecuta la migraci√≥n hacia atr√°s (downgrade/rollback).
    
    Esta funci√≥n revierte todas las operaciones realizadas en upgrade()
    para restaurar la base de datos al estado anterior.
    """
    backup_schema = None
    
    try:
        log_migration_start("DOWNGRADE")
        
        # 1. Validar prerequisitos
        if not validate_prerequisites():
            raise Exception("Prerequisitos no cumplidos para rollback")
        
        # 2. Advertencia especial para rollback en producci√≥n
        env = migration_info['environment']
        if env == 'production':
            logger.warning("‚ö†Ô∏è  ROLLBACK EN PRODUCCI√ìN - Procediendo con precauci√≥n")
        
        # 3. Validar integridad pre-rollback
        if MIGRATION_CONFIG['validate_data_integrity']:
            if not validate_data_integrity_pre():
                logger.warning("Advertencias en validaci√≥n pre-rollback")
        
        # 4. Crear backup antes del rollback
        backup_schema = backup_critical_data()
        
        # 5. Ejecutar operaciones de rollback
        logger.info("Ejecutando operaciones de rollback...")
        
        # ====================================================================
        # OPERACIONES DE ROLLBACK - ORDEN INVERSO AL UPGRADE
        # ====================================================================
        ${downgrades if downgrades else "# TODO: Agregar operaciones de rollback"}
        
        # Ejemplo de operaciones de rollback (orden inverso):
        # 
        # # Eliminar constraint
        # op.drop_constraint('fk_tabla_referencia', 'tabla', type_='foreignkey')
        # 
        # # Eliminar √≠ndice
        # op.drop_index('idx_tabla_columna')
        # 
        # # Eliminar columna
        # op.drop_column('tabla_existente', 'nueva_columna')
        # 
        # # Eliminar tabla
        # op.drop_table('nueva_tabla')
        
        logger.info("‚úì Operaciones de rollback completadas")
        
        # 6. Validar integridad post-rollback
        if MIGRATION_CONFIG['validate_data_integrity']:
            if not validate_data_integrity_post():
                raise Exception("Fallo en validaci√≥n de integridad post-rollback")
        
        # 7. Limpiar cache
        clear_application_cache()
        
        # 8. Limpiar backup temporal
        cleanup_backup(backup_schema)
        
        # 9. Enviar notificaci√≥n de √©xito
        send_migration_notification("downgrade", True, 
            f"‚Ü©Ô∏è Rollback ejecutado exitosamente en {migration_info['environment']}")
        
        log_migration_end("DOWNGRADE", True)
        
    except Exception as e:
        logger.error(f"‚úó Error durante downgrade: {e}")
        
        # Mantener backup en caso de error
        if backup_schema:
            logger.info(f"Backup preservado para recuperaci√≥n: {backup_schema}")
        
        # Enviar notificaci√≥n de error cr√≠tico
        send_migration_notification("downgrade", False, 
            f"üö® ERROR CR√çTICO EN ROLLBACK: {str(e)}\nüíæ Backup: {backup_schema or 'No'}\nüìû Contactar DBA inmediatamente")
        
        log_migration_end("DOWNGRADE", False)
        raise


# ============================================================================
# FUNCIONES AUXILIARES ESPEC√çFICAS DEL ECOSISTEMA
# ============================================================================

def migrate_user_data_batch(batch_size: int = 1000) -> None:
    """
    Migra datos de usuarios en lotes para operaciones grandes.
    """
    connection = get_connection()
    
    # Obtener total de registros
    result = connection.execute(text("SELECT COUNT(*) FROM users"))
    total_users = result.fetchone()[0]
    
    logger.info(f"Migrando {total_users} usuarios en lotes de {batch_size}")
    
    offset = 0
    while offset < total_users:
        # Procesar lote
        logger.info(f"Procesando lote {offset//batch_size + 1}: registros {offset}-{offset+batch_size}")
        
        # Aqu√≠ ir√≠a la l√≥gica espec√≠fica de migraci√≥n de datos
        # Por ejemplo:
        # connection.execute(text(f"""
        #     UPDATE users 
        #     SET new_column = old_column 
        #     WHERE id IN (
        #         SELECT id FROM users 
        #         ORDER BY id 
        #         LIMIT {batch_size} OFFSET {offset}
        #     )
        # """))
        
        offset += batch_size


def update_entrepreneur_metrics() -> None:
    """
    Actualiza m√©tricas de emprendedores despu√©s de cambios estructurales.
    """
    try:
        connection = get_connection()
        
        # Actualizar m√©tricas agregadas
        connection.execute(text("""
            INSERT INTO analytics.entrepreneur_metrics (entrepreneur_id, metric_date, projects_count, meetings_count)
            SELECT 
                e.id,
                CURRENT_DATE,
                COUNT(DISTINCT p.id),
                COUNT(DISTINCT m.id)
            FROM entrepreneurs e
            LEFT JOIN projects p ON e.id = p.entrepreneur_id
            LEFT JOIN meetings m ON e.user_id = m.created_by
            GROUP BY e.id
            ON CONFLICT (entrepreneur_id, metric_date) 
            DO UPDATE SET 
                projects_count = EXCLUDED.projects_count,
                meetings_count = EXCLUDED.meetings_count,
                updated_at = NOW()
        """))
        
        logger.info("‚úì M√©tricas de emprendedores actualizadas")
        
    except Exception as e:
        logger.warning(f"Error actualizando m√©tricas de emprendedores: {e}")


def refresh_materialized_views() -> None:
    """
    Actualiza vistas materializadas del ecosistema.
    """
    materialized_views = [
        'analytics.user_activity_summary',
        'analytics.project_status_overview', 
        'analytics.monthly_metrics',
        'reporting.entrepreneur_performance',
    ]
    
    connection = get_connection()
    
    for view in materialized_views:
        try:
            connection.execute(text(f"REFRESH MATERIALIZED VIEW CONCURRENTLY {view}"))
            logger.info(f"‚úì Vista materializada actualizada: {view}")
        except Exception as e:
            logger.warning(f"Error actualizando vista {view}: {e}")


# ============================================================================
# METADATA FINAL
# ============================================================================

# Informaci√≥n adicional para auditoria
__migration_metadata__ = {
    'revision': revision,
    'description': ${repr(message)},
    'created_at': '${create_date}',
    'file_template_version': '2.1.0',
    'ecosistema_version': '1.0.0',
    'safety_checks_enabled': True,
    'auto_backup_enabled': MIGRATION_CONFIG['requires_backup'],
    'notifications_enabled': True,
}